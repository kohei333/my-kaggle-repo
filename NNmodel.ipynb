{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics, preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/work/CatInDat2/data/train.csv', index_col='id')\n",
    "test = pd.read_csv('/work/CatInDat2/data/test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testデータにもtargetカラムを作っているだけ\n",
    "test[\"target\"] = -1\n",
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "\n",
    "features = [x for x in train.columns if x not in [\"id\", \"target\"]]\n",
    "\n",
    "for feat in features:\n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "    data[feat] = lbl_enc.fit_transform(data[feat].fillna(\"-1\").astype(str).values)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train = data[data.target != -1].reset_index(drop=True)\n",
    "test = data[data.target == -1].reset_index(drop=True)\n",
    "#test.loc[:, features].values.shape[1]=23\n",
    "#featuresの数\n",
    "#すなわち、各列をndarray型でlistにしていっている\n",
    "test_data = [test.loc[:, features].values[:, k] \n",
    "             for k in range(test.loc[:, features].values.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    def fallback_auc(y_true, y_pred):\n",
    "        try:\n",
    "            return metrics.roc_auc_score(y_true, y_pred)\n",
    "        except:\n",
    "            return 0.5\n",
    "    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)\n",
    "\n",
    "def create_model(data, catcols):    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for c in catcols:\n",
    "        num_unique_values = int(data[c].nunique())\n",
    "        embed_dim = int(min(np.ceil((num_unique_values)/2), 50))\n",
    "        inp = layers.Input(shape=(1,))\n",
    "        out = layers.Embedding(num_unique_values + 1, embed_dim, name=c)(inp)\n",
    "        out = layers.SpatialDropout1D(0.3)(out)\n",
    "        out = layers.Reshape(target_shape=(embed_dim, ))(out)\n",
    "        inputs.append(inp)\n",
    "        outputs.append(out)\n",
    "        \n",
    "    x = layers.Concatenate()(outputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(300, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(300, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(300, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(300, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    y = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oof_preds = np.zeros((len(train)))\n",
    "test_preds = np.zeros((len(test)))\n",
    "\n",
    "#skf = StratifiedKFold(n_splits=50)\n",
    "#for Stacking\n",
    "skf = StratifiedKFold(n_splits=50, shuffle=True, random_state=42)\n",
    "va_idxes = []\n",
    "preds = []\n",
    "for train_index, test_index in skf.split(train, train.target.values):\n",
    "    X_train, X_test = train.iloc[train_index, :], train.iloc[test_index, :]\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    y_train, y_test = X_train.target.values, X_test.target.values\n",
    "    model = create_model(data, features)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[auc])\n",
    "    \n",
    "    #features : targetを除いた全カラム\n",
    "    X_train = [X_train.loc[:, features].values[:, k] for k in range(X_train.loc[:, features].values.shape[1])]\n",
    "    X_test = [X_test.loc[:, features].values[:, k] for k in range(X_test.loc[:, features].values.shape[1])]\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=5,\n",
    "                                 verbose=1, mode='max', baseline=None, restore_best_weights=True)\n",
    "    rlr = callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5,\n",
    "                                      patience=3, min_lr=1e-6, mode='max', verbose=1)\n",
    "    \n",
    "    model.fit(X_train,\n",
    "              utils.to_categorical(y_train),\n",
    "              validation_data=(X_test, utils.to_categorical(y_test)),\n",
    "              verbose=1,\n",
    "              batch_size=1024,\n",
    "              callbacks=[es, rlr],\n",
    "              epochs=100\n",
    "             )\n",
    "    \n",
    "    valid_fold_preds = model.predict(X_test)[:, 1]\n",
    "    preds.append(valid_fold_preds) ##for Stack\n",
    "    va_idxes.append(test_index)    ##for Stack   \n",
    "    test_fold_preds = model.predict(test_data)[:, 1]\n",
    "    oof_preds[test_index] = valid_fold_preds.ravel()\n",
    "    test_preds += test_fold_preds.ravel()\n",
    "    print(metrics.roc_auc_score(y_test, valid_fold_preds))\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_idxes = np.concatenate(va_idxes)\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "order = np.argsort(va_idxes)\n",
    "pred_train = preds[order]\n",
    "\n",
    "\n",
    "test_preds /= 50\n",
    "\n",
    "#保存\n",
    "\n",
    "np.save('/Users/takaikouhei/Downloads/Embedding_Stacking/Embed_pred_train2', pred_train)\n",
    "np.save('/Users/takaikouhei/Downloads/Embedding_Stacking/Embed_test_pred2', test_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
